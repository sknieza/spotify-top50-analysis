{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411d63e8",
   "metadata": {},
   "source": [
    "# Spotify Top 50 tracks analysis\n",
    "\n",
    "\n",
    "## Context\n",
    "\n",
    "Imagine you're a data analyst working for Spotify. Your team is responsible for content analysis and in this quarter you've decided to analyze Spotify's top hits to quantify what makes a hit song. Your team's product manager has many ideas and has prepared a list of questions (requirements) that she wants you to answer. After reviewing the list of over 20 questions, you are not in a good mood - it will take a couple of days to get all the answers. \n",
    "\n",
    "Luckily, a few days ago, an experienced data scientist working in your team queried the top 50 tracks for her machine learning project and agreed to share the data with you. This is a great help - your SQL skills are not too sharp yet, and you don't yet know where to find all the relevant tables in your data warehouse. With this dataset, you are confident that you'll be able to answer all of your PM's questions, plus maybe even look into some additional points of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9bc03b",
   "metadata": {},
   "source": [
    "## Preparing for exploratory data analysis\n",
    "\n",
    "First, we'll import `numpy` and `pandas` libraries for our analysis. After reading the `.csv` dataset, we'll print top 5 tracks to understand the features of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b256866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "top50 = pd.read_csv(\"datasets/spotifytoptracks.csv\")\n",
    "top50.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27820f88",
   "metadata": {},
   "source": [
    "## 00 Data cleaning\n",
    "\n",
    "Perform data cleaning by:\n",
    "- Handling missing values.\n",
    "- Removing duplicate samples and features.\n",
    "- Treating the outliers.\n",
    "\n",
    "### Missing values\n",
    "\n",
    "We'll check for missing values using the combination of `isna()` and `sum()` methods. If it returns zero, we have no missing values to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02fc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af59b09",
   "metadata": {},
   "source": [
    "### Duplicate samples and features\n",
    "\n",
    "Again, using the `duplicated()` method, we check if there are repetitive entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc06dbb",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "So far, we have no duplicate rows and no missing values. However, we still need to find out, if we have any outliers in different columns. Here I define the function `find_outliers(df)` which will use interquartile range (IQR) and the formula to find if there are values that are below q1 by 1.5\\*IQR or above q3 by 1.5\\*IQR.\n",
    "\n",
    "Using the following function, we discover if there are outliers in seprate columns, and using DataFrame methods we extract the songs which are outliers at least in one feature (column). We return the boolean DataFrame, indicating there songs are outliers compared to the whole `top50` dataset, counting outlier dimension in column `out_dim_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee1a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = list(top50.columns[5:16].values)\n",
    "\n",
    "def find_outliers_IQR(df, dim):\n",
    "    temp = []\n",
    "    for d in dim:\n",
    "        q1=df[d].quantile(0.25)\n",
    "        q3=df[d].quantile(0.75)\n",
    "        IQR=q3-q1\n",
    "        outliers = df[d][((df[d]<(q1-1.5*IQR)) | (df[d]>(q3+1.5*IQR)))]\n",
    "        temp.append(outliers)\n",
    "    outliers_concatenated = pd.concat(temp, axis=1)\n",
    "    return outliers_concatenated\n",
    "\n",
    "outliers = find_outliers_IQR(top50, dim)\n",
    "out_sorted = outliers.sort_index().notna()\n",
    "out_sorted['out_dim_count'] = out_sorted.sum(axis=1)\n",
    "outlier_tracks = top50.loc[out_sorted.index, ['artist', 'album', 'track_name']]\n",
    "out_sorted = pd.concat([outlier_tracks, out_sorted], axis=1)\n",
    "out_sorted.sort_values(['out_dim_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7b456",
   "metadata": {},
   "source": [
    "From this initial analysis we see that Billie Elish 'everything i wanted' clearly differs from the rest as it exceeds in three dimensions – instrumentalness, acousticness and loudness. But that's only our initial scoping of the dataframe. Half of its songs are outliers in at least one dimension, meaning that dealing with them early on might siognificantly reduce our sample size. So, we decided not to tinker with them now, and proceed with the project manager's questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066d5fcf",
   "metadata": {},
   "source": [
    "## 01 Data analysis\n",
    "\n",
    "### 1. How many observations are there in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba31e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = len(top50.index)\n",
    "features = len(top50.columns)\n",
    "observations = sample * features\n",
    "print(f\"There are {sample} samples over {features} features, resulting in {observations} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd110b4",
   "metadata": {},
   "source": [
    "### 2. How many features this dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ad33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {features} features in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1bdee",
   "metadata": {},
   "source": [
    "### 3. Which of the features are categorical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1557e771",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.select_dtypes(include=['category']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3db8f91",
   "metadata": {},
   "source": [
    "A quick stop here: apparently, we have no categorical data in columns, even though `genre` values are clearly repetitive and can divide the data into categories. We may convert it to categorical data, but is it useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cce7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ba69c",
   "metadata": {},
   "source": [
    "We see that ithe columns has some multiple genres per cell, but only 10 observations are very 'exotic' – that is, have some strange combinations of genres. It might be worth taking a shot at conversion for usability purposes later in our exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebebb1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50['genre'] = top50['genre'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15df57d9",
   "metadata": {},
   "source": [
    "Let's check, if we successfully converted genres into categorical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca7f025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following features are categorical: \")\n",
    "top50.select_dtypes(include=['category']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267850c0",
   "metadata": {},
   "source": [
    "### 4. Which of the features are numeric?\n",
    "\n",
    "To answer this question, we select columns with data types `int64` and `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da695105",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = pd.Series(top50.select_dtypes(include=['int64', 'float64']).columns)\n",
    "\n",
    "print(\"The following features are numerical: \")\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1675b9",
   "metadata": {},
   "source": [
    "### 5. Are there any artists that have more than 1 popular track? If yes, which and how many?\n",
    "\n",
    "For this, we look for repetitions of artist name in the `artist` column, and return only those values the count of which is more than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_several_tracks = top50['artist'].value_counts()\n",
    "\n",
    "print(\"The following artists have more than one track in the top50 list: \")\n",
    "artists_several_tracks[artists_several_tracks > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87034825",
   "metadata": {},
   "source": [
    "### 6. Who was the most popular artist?\n",
    "\n",
    "There are two ways to answer this question:\n",
    "1. By top hit count, we already saw that Billie Eilish, Dua Lipa and Travis Scott has the most tracks in the list;\n",
    "2. Another way is to take the top row of the list.\n",
    "\n",
    "As there is no `no_of_plays` feature, which would indicate how popular the track was, we assume that ordering by index represents the popularity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047e2f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following is the most popular artist with the first position in chart: \")\n",
    "\n",
    "top50['artist'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e60987",
   "metadata": {},
   "source": [
    "### 7. How many artists in total have their songs in the top 50?\n",
    "\n",
    "For this, we'll look for unique entries in the `artist` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_count = len(top50['artist'].unique())\n",
    "print(f\"{artist_count} artists have their songs in the top 50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338666a7",
   "metadata": {},
   "source": [
    "### 8. Are there any albums that have more than 1 popular track? If yes, which and how many?\n",
    "\n",
    "In this case, we need to group by the `album` column, treating repetitions as a song count. If it exceeds 1, we assume the album has more than one song in top 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_several_tracks = top50.groupby(['album', 'artist']).size().reset_index(name='song_count')\n",
    "with_multiple_tracks = albums_several_tracks[albums_several_tracks['song_count'] > 1]\n",
    "\n",
    "print(\"These albums have more than one track on the top 50 list: \")\n",
    "with_multiple_tracks.sort_values(by='song_count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed15187",
   "metadata": {},
   "source": [
    "### 9. How many albums in total have their songs in the top 50?\n",
    "\n",
    "We use the `unique` method to count all distinct values – the length returns us the number of albums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "album_count = len(top50['album'].unique())\n",
    "print(f\"There are {album_count} albums in top 50.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f23169",
   "metadata": {},
   "source": [
    "### 10. Which tracks have a danceability score above 0.7?\n",
    "\n",
    "We select the dataframe with `artist`, `track_name` and `danceability` columns. We then apply the condition, based on the `danceability` values, and sort the resulting dataframe by them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c5f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "danceability_score = top50[['artist', 'track_name', 'danceability']]\n",
    "high_danceability = danceability_score[danceability_score['danceability'] > 0.7].sort_values(by='danceability', ascending=False)\n",
    "\n",
    "print(\"The following are the tracks with high danceability score: \")\n",
    "high_danceability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8750cf",
   "metadata": {},
   "source": [
    "### 11. Which tracks have a danceability score below 0.4?\n",
    "\n",
    "We use the similar approach here, only changing the condition and sorting in ascending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662252a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_danceability = danceability_score[danceability_score['danceability'] < 0.4].sort_values(by='danceability', ascending=True)\n",
    "\n",
    "print(\"The following are the tracks with the low danceability score: \")\n",
    "low_danceability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab416124",
   "metadata": {},
   "source": [
    "### 12. Which tracks have their loudness above -5?\n",
    "\n",
    "Here we follow the `danceability` logic, only changing the features and conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness_score = top50[['artist', 'track_name', 'loudness']]\n",
    "loud_tracks = loudness_score[loudness_score['loudness'] > -5].sort_values(by='loudness', ascending=False)\n",
    "\n",
    "print(\"These are the loudest tracks in the top 50: \")\n",
    "loud_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce196bd9",
   "metadata": {},
   "source": [
    "### 13. Which tracks have their loudness below -8?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiet_tracks = loudness_score[loudness_score['loudness'] < -8].sort_values(by='loudness', ascending=False)\n",
    "\n",
    "print(\"These are the quietest tracks in the top 50: \")\n",
    "quiet_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f6b373",
   "metadata": {},
   "source": [
    "### 14. Which track is the longest?\n",
    "\n",
    "For this, again, we select a subset of the original data frame, and indicate the maximum value in the `duration_ms` column, by using `idxmax()` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_duration = top50[['artist', 'track_name', 'duration_ms']]\n",
    "longest_track = track_duration['duration_ms'].idxmax()\n",
    "longest_track\n",
    "track_duration.loc[longest_track]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4faf3",
   "metadata": {},
   "source": [
    "Not the user-friendlist format, let's convert into `minutes:seconds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_minutes_seconds(duration):\n",
    "    minutes = duration // 60000\n",
    "    seconds = round((((duration / 60000) - (duration // 60000)) * 60))\n",
    "    return f\"{minutes}:{seconds}\"\n",
    "\n",
    "long_duration = track_duration.loc[longest_track]['duration_ms']\n",
    "\n",
    "print(f\"The following is the longest track of the top 50: \\n \\n {track_duration.loc[longest_track]} \\n\")\n",
    "\n",
    "print(f\"Length in minutes: {to_minutes_seconds(long_duration)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7cf64a",
   "metadata": {},
   "source": [
    "### 15. Which track is the shortest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_track = track_duration['duration_ms'].idxmin()\n",
    "shortest_track\n",
    "track_duration.loc[shortest_track]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9fd2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_duration = track_duration.loc[shortest_track]['duration_ms']\n",
    "\n",
    "print(f\"The following is the shortest track of the top 50: \\n \\n {track_duration.loc[shortest_track]} \\n\")\n",
    "\n",
    "print(f\"Length in minutes: {to_minutes_seconds(short_duration)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899c2208",
   "metadata": {},
   "source": [
    "### 16. Which genre is the most popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d76403",
   "metadata": {},
   "source": [
    "We have already touched upon this question when considering categorical variables. Let's redo the Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467cfb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0bde78",
   "metadata": {},
   "source": [
    "From data we see that Pop dominates with Hip-hop/Rap close behind, especially considering sub-genres with one or two observations (chamber pop, hip-hop / trap, etc.) Sufficient here is to say, that pop and hip-hop/rap genres significantly dominates over the 'distinct' genre-level alternatives such as electronic music, alternative and R&B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27bc55",
   "metadata": {},
   "source": [
    "### 17. Which genres have just one song on the top 50?\n",
    "\n",
    "For this, let's use the condition, transforming genres into indices, and resulting counts as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45405f34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "song_genre = top50[['artist', 'track_name', 'genre']]\n",
    "genre_list = top50['genre'].value_counts()\n",
    "single_track_per_genre = genre_list[genre_list < 2].index\n",
    "\n",
    "unique_genre_tracks = song_genre[song_genre['genre'].isin(single_track_per_genre)]\n",
    "\n",
    "print(\"The following genres only appear once in the dataset: \")\n",
    "unique_genre_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc07a3d",
   "metadata": {},
   "source": [
    "Short note here. Like we discovered already in dealing with categorical data type, some of these genres are just combination of some of the other genres. These exotic sets actually raise a question, how we deal with this: do we treat the combination as unique genre, or should we somehow look for the ways to disassemble them into separate features? But if so, which genre should be taken as the main one? This caveat is only a side note for further analysis, as we'll now focus on the 'pure' genres, which make up the majority of the top 50 list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2e652",
   "metadata": {},
   "source": [
    "### 18. How many genres in total are represented in the top 50?\n",
    "\n",
    "Disregarding philosophical considerations on what defines a genre in the last question, we simply use the `unique` method here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c6b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(top50['genre'].unique())} genres in the top 50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be23c75",
   "metadata": {},
   "source": [
    "### 19. Which features are strongly positively correlated?\n",
    "\n",
    "We have to arbitrarily select the threshold which would indicate the strong correlation. We will take the r=0.75 as threshold, and indicate that if features have r>0.75, there is a strong correlation between them. The same will go for negative correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = top50.iloc[:, 5:16]\n",
    "features.corr() > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3606c9",
   "metadata": {},
   "source": [
    "We see that there are following correlations:\n",
    "\n",
    "- energy – loudness\n",
    "\n",
    "This proves the truism: the louder the music, the more energetic the vibe. We cannot indicate the causation, though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19332f4c",
   "metadata": {},
   "source": [
    "### 20. Which features are strongly negatively correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = top50.iloc[:, 5:16]\n",
    "features.corr() < -0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d164199a",
   "metadata": {},
   "source": [
    "Choosing a threshold of r=0.75 yielded no results, thus we lowered the bar to r=0.5 just to see some moderate patterns. Those are:\n",
    "\n",
    "- energy – acousticness\n",
    "- instrumentalness – loudness\n",
    "\n",
    "From these initial inferences we can conclude that the energy of the track is strongly positively related to loudness, while negatively correlates with acousticness – acoustic songs are calmer. Also, instrumental tracks seem to be quieter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8392d5",
   "metadata": {},
   "source": [
    "### 21. Which features are not correlated?\n",
    "\n",
    "We use the same conditional approach here, setting the range of low correlation to (-0.25, 0.25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73b1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = features.corr()\n",
    "correlation_matrix\n",
    "no_correlation_features = (correlation_matrix > -0.25) & (correlation_matrix < 0.25)\n",
    "no_correlation_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa601006",
   "metadata": {},
   "source": [
    "In short, it's hard to answer which features are not correlated, given only r = (-0.25, 0.25) range. We clearly see that duration and tempo has no effect on other features, except the stronger relationship between speechiness and duration. Other dimensions have weak-to-moderate relationship, but no outliers there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a04a4",
   "metadata": {},
   "source": [
    "### 22. How does the danceability score compare between Pop, Hip-Hop/Rap, Dance/Electronic, and Alternative/Indie genres?\n",
    "\n",
    "For this, we'll print summaries of descriptive statistics, using the `describe` method. We also indicate key genres in a separate list for the easier usability further on. For more informative appraoch, we'll also add `median` manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_genres = ['Pop', 'Hip-Hop/Rap', 'Dance/Electronic', 'Alternative/Indie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c066419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "danceability_by_key_genre = top50[['danceability', 'genre']].set_index('genre').loc[key_genres]\n",
    "for genre in key_genres:\n",
    "    print(genre, '\\n', danceability_by_key_genre.loc[genre].describe(), '\\n', \"median: \", danceability_by_key_genre.loc[genre].median(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e686b6",
   "metadata": {},
   "source": [
    "On average, we see that Hip-Hop/Rap and Dance/Electronic tracks have a higher danceability score. Hip-Hop/Rap also has the most danceable track (0.896) of all genres. The least danceable genre is Alternative/Indie, which also has the least danceable track (0.459)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9af66b",
   "metadata": {},
   "source": [
    "### 23. How does the loudness score compare between Pop, Hip-Hop/Rap, Dance/Electronic, and Alternative/Indie genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loudness_by_key_genre = top50[['loudness', 'genre']].set_index('genre').loc[key_genres]\n",
    "for genre in key_genres:\n",
    "    print(genre, '\\n', loudness_by_key_genre.loc[genre].describe(), '\\n', \"median: \", loudness_by_key_genre.loc[genre].median(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88966d55",
   "metadata": {},
   "source": [
    "As expected, the Dance/Electronic music is the loudest, while Hip-Hop/Rap has the quietest songs. However, if we compare the median values, Alternative/Indie has the higher middle value, meaning that there are really loud songs among Dance/Electronic, which skew the data, or the majority of Alternative/Indie songs tend to be louder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21504cce",
   "metadata": {},
   "source": [
    "### 24. How does the acousticness score compare between Pop, Hip-Hop/Rap, Dance/Electronic, and Alternative/Indie genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419fa2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "acousticness_by_key_genre = top50[['acousticness', 'genre']].set_index('genre').loc[key_genres]\n",
    "for genre in key_genres:\n",
    "    print(genre, '\\n', acousticness_by_key_genre.loc[genre].describe(), '\\n', \"median: \", acousticness_by_key_genre.loc[genre].median(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb0fb9",
   "metadata": {},
   "source": [
    "The most acoustic genre is Alternative/Indie, having both the highest mean and median values, the latter also surpassing the former – meaning that the values are in general on the higher side. Dance/Electronic tracks are the least acoustic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb502778",
   "metadata": {},
   "source": [
    "## Some takeaways and considerations\n",
    "\n",
    "### What did we learn from this analysis?\n",
    "\n",
    "1. Billie Eilish, Travis Scott and Dua Lipa has the most songs on the top 50 list (3 each), meaning that together they make up almost a fifth of the chart. Given that there are 40 artists in total, less than 10% of artists make up for 20% of total tracks of the list;\n",
    "2. Billie Eilish song 'everything i wanted' is an outlier in the most – 3 – dimensions. However, 25 of the tracks are outliers in at least one dimension;\n",
    "3. Four genres cover almost 4/5 (36 out of 50) of tracks, but we should be aware that the majority of less frequent genres are the combination of some other genres, and these should be treated differently, either by cleaning and manipulation. Notice that from 'pure' genres R&B/Soul has only two samples, which shows its declining popularity – even though the most popular track is R&B;\n",
    "4. Energy and loudness features correlate strongly, while we see the negative correlation between energy and acousticness, instrumentalness and loudness (but the r threshold here is lower). Tempo and track duration does not influence other features of the track;\n",
    "5. Some genre-related insights on several features:\n",
    "- Hip-Hop/Rap and Dance/Electronic tracks have a higher danceability score. Hip-Hop/Rap also has the most danceable track (0.896) of all genres. The least danceable genre is Alternative/Indie, which also has the least danceable track (0.459);\n",
    "- As expected, the Dance/Electronic music is the loudest, while Hip-Hop/Rap has the quietest songs. However, if we compare the median values, Alternative/Indie has the higher middle value, meaning that there are really loud songs among Dance/Electronic, which skew the data, or the majority of Alternative/Indie songs tend to be louder;\n",
    "- The most acoustic genre is Alternative/Indie, having both the highest mean and median values, the latter also surpassing the former – meaning that the values are in general on the higher side. Dance/Electronic tracks are the least acoustic.\n",
    "\n",
    "### How to improve it and further things to look at:\n",
    "\n",
    "1. We didn't have the listener / play count in this dataset, meaning that we had to trust indexing as the aggregated value for popularity. It would be interesting to see the relationship between play count and other features in numerical terms;\n",
    "2. We could also tinker the genre approach, building more general categories (for example, Pop category including nu-pop or disco-pop). The regex and mapping could be employed here to add several genre columns;\n",
    "3. The `key` feature also is interesting to analyze, especially in terms of valence or energy. Initially we saw no correlation, but maybe knowing major or minor tonality could provide us with a hint of how top music sounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d9ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
